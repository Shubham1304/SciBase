{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Learning with kernels: support vector machines, regularization, optimization, and beyond\n",
      "1\n",
      "An introduction to support vector machines and other kernel-based learning methods\n",
      "1\n",
      "LIBSVM: a library for support vector machines\n",
      "1\n",
      "Unsupervised learning\n",
      "1\n",
      "Elements of information theory\n",
      "1\n",
      "Data Mining: Practical machine learning tools and techniques\n",
      "1\n",
      "Modern applied statistics with S-PLUS\n",
      "1\n",
      "Introduction to information retrieval\n",
      "1\n",
      "Convex optimization\n",
      "1\n",
      "Gaussian processes in machine learning\n"
     ]
    }
   ],
   "source": [
    "import os , sys\n",
    "from selenium  import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import errno\n",
    "import requests\n",
    "import webbrowser\n",
    "url=\"https://scholar.google.co.in/scholar?oi=bibs&hl=en&cites=8608559880368280977,257377035427477106,13538606778381662047,7584568690943495592,13074838339646797994\"\n",
    "source_code = requests.get(url)\n",
    "source_text = source_code.text\n",
    "soup = BeautifulSoup(source_text,\"lxml\")\n",
    "for ele in soup.find_all(\"div\",{\"class\":\"gs_ri\"}):  #for the whole class\n",
    "    #redditAll1 = ele1.find_all(\"a\")\n",
    "    #print(len(redditAll1))\n",
    "    for ele1 in ele.find_all(\"h3\",{'class':\"gs_rt\"}):  #for the name of paper\n",
    "        redditAll1 = ele1.find_all(\"a\")\n",
    "        print(len(redditAll1))\n",
    "        for a1 in ele1.find_all('a'):\n",
    "            print(a1.text)\n",
    "            #redditAll1 = ele1.find_all(\"a\")\n",
    "            #print(len(redditAll1))\n",
    "            #leng1=len(redditAll1)\n",
    "            #str1.append(\"\\\"\"+a1.text+\"\\\":[{\")\n",
    "            #leng1-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor of Electrical Engineering, Computer Science, and Management Science, Stanford\n"
     ]
    }
   ],
   "source": [
    "import os , sys\n",
    "from selenium  import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import errno\n",
    "import requests\n",
    "import webbrowser\n",
    "url='https://scholar.google.co.in/citations?user=GExyiRkAAAAJ&hl=en&oi=sra'\n",
    "source_code = requests.get(url)\n",
    "source_text = source_code.text\n",
    "soup = BeautifulSoup(source_text,\"lxml\")\n",
    "inst=soup.find(\"div\",{\"class\":\"gsc_prf_il\"})\n",
    "print(inst.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the author you want to search:\n",
      "vapnik\n",
      "The Nature of Statistical Learning Theory\n",
      "https://scholar.google.co.in/citations?user=vtegaJgAAAAJ&hl=en\n",
      "[BOOK][B] Learning with kernels: support vector machines, regularization, optimization, and beyond\n",
      "The Nature of Statistical Learning Theory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsource2=requests.get(url)\\nsource2_text=source2.text\\nsoup2=BeautifulSoup(source2_text,\\'lxml\\')\\nele2=soup2.find(\"a\",{\"class\":\"gsc_a_t\"})\\n#print(ele2)\\nsoup2.prettify()'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os , sys\n",
    "from selenium  import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import errno\n",
    "print(\"Enter the name of the author you want to search:\")\n",
    "search=input()\n",
    "url=\"https://scholar.google.co.in/citations?view_op=search_authors&mauthors=\" + search\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "browser.get(url)\n",
    "elem = WebDriverWait(browser,10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"gsc_sa_ccl\"]/div/div/h3/a/span')))\n",
    "source = browser.page_source\n",
    "button = browser.find_element_by_css_selector('#gsc_sa_ccl > div > div > h3 > a > span')\n",
    "button.click()\n",
    "element = WebDriverWait(browser,30).until(EC.visibility_of_element_located((By.CSS_SELECTOR,'#gsc_a_b > tr:nth-child(1) > td.gsc_a_t > a')))\n",
    "source1=browser.page_source\n",
    "soup = BeautifulSoup(source1,'html.parser')\n",
    "url=browser.current_url\n",
    "raw_name = soup.find(\"td\",{\"class\":\"gsc_a_t\"})\n",
    "name=raw_name.find(\"a\",{\"class\":\"gsc_a_at\"})\n",
    "print(name.text)\n",
    "#str1=[]\n",
    "#str1.append(\"{\\\"\"+name.text+\"\\\":{\")\n",
    "\n",
    "\n",
    "button2 = browser.find_element_by_css_selector('tr.gsc_a_tr:nth-child(1) > td:nth-child(2) > a:nth-child(1)')\n",
    "button2.click()\n",
    "#url = browser.current_url\n",
    "source2=browser.page_source\n",
    "soup2 = BeautifulSoup(source2,'html.parser')\n",
    "print(url)\n",
    "ele=soup2.find(\"h3\",{\"class\":\"gs_rt\"})\n",
    "print(ele.text)\n",
    "browser.get(url)\n",
    "\n",
    "raw_name2 = soup.find(\"td\",{\"class\":\"gsc_a_t\"})\n",
    "name2=raw_name2.find(\"a\",{\"class\":\"gsc_a_at\"})\n",
    "print(name2.text)\n",
    "\n",
    "button2 = browser.find_element_by_css_selector('tr.gsc_a_tr:nth-child(1) > td:nth-child(2) > a:nth-child(1)')\n",
    "button2.click()\n",
    "\n",
    "'''\n",
    "source2=requests.get(url)\n",
    "source2_text=source2.text\n",
    "soup2=BeautifulSoup(source2_text,'lxml')\n",
    "ele2=soup2.find(\"a\",{\"class\":\"gsc_a_t\"})\n",
    "#print(ele2)\n",
    "soup2.prettify()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
